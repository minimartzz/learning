{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Tasks (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 18/12/2025   | Martin | Create  | Notebook created for various NLP tasks using HF | \n",
    "| 22/12/2025   | Martin | Update  | Continued translation. Up to before training model | \n",
    "| 23/12/2025   | Martin | Update  | Completed translation. Started on summarisation task | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [1. Translation](#1-translation)\n",
    "* [2. Summarisation](#2-summarisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Tackle common NLP problems using LLMs built using the HF package:\n",
    "\n",
    "1. Translation\n",
    "2. Summarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Translation\n",
    "\n",
    "- Seq-2-Seq task\n",
    "- Finetune existing language model (mT5, mBART, Marian - here)\n",
    "\n",
    "<u>Components</u>\n",
    "\n",
    "- Marian: English to French translation model\n",
    "- KDE4 dataset: Localised files for KDE (Apps for Linux desktops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "  pipeline,\n",
    "  get_scheduler,\n",
    "  AutoTokenizer,\n",
    "  AutoModelForSeq2SeqLM,\n",
    "  DataCollatorForSeq2Seq,\n",
    "  Seq2SeqTrainingArguments,\n",
    "  Seq2SeqTrainer,\n",
    ")\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from accelerate import Accelerator\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "SEED = 20\n",
    "MAXLEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 139666\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"kde4\", lang1=\"en\", lang2=\"zh_CN\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 125699\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 13967\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets = raw_datasets['train'].train_test_split(train_size=0.9, seed=SEED)\n",
    "split_datasets['validation'] = split_datasets.pop('test')\n",
    "split_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains 2 statements one for each language. The KDE4 dataset translates many of the technical terms to the corresponding language, but the pretrained model does not do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Installation prefix for Qt', 'zh_CN': 'Qt ÁöÑÂÆâË£ÖÂâçÁºÄ'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KDE4 dataset\n",
    "split_datasets['train'][1]['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Â∞ÜÂΩìÂâçÂÖâÊ†á‰ΩçÁΩÆ‰∏äÁöÑÂâ™Ë¥¥ÊùøÂÜÖÂÆπÁ≤òË¥¥Âà∞ÁºñËæëÂ≠óÊÆµ‰∏≠„ÄÇ'}]\n"
     ]
    }
   ],
   "source": [
    "# Pretrained model\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-zh\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint)\n",
    "print(translator(\"Pastes the clipboard contents at the current cursor position into the edit field.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pretrained components\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors='pt')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Installation prefix for Qt', 'zh_CN': 'Qt ÁöÑÂÆâË£ÖÂâçÁºÄ'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets['train'][1]['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [54596, 2765, 594, 10110, 15, 8, 632, 60, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [8, 632, 60, 8, 12, 9613, 637, 56891, 0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of splitting dataset and passing through tokenizer\n",
    "en_sentence = split_datasets['train'][1]['translation']['en']\n",
    "cn_sentence = split_datasets['train'][1]['translation']['zh_CN']\n",
    "\n",
    "inputs = tokenizer(en_sentence, text_target=cn_sentence)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "def preprocess(examples):\n",
    "  inputs = [ex['en'] for ex in examples['translation']]\n",
    "  targets = [ex['zh_CN'] for ex in examples['translation']]\n",
    "  model_inputs = tokenizer(inputs, text_target=targets, max_length=MAXLEN, truncation=True)\n",
    "\n",
    "  return model_inputs\n",
    "\n",
    "tokenized_dataset = split_datasets.map(\n",
    "  preprocess,\n",
    "  batched=True,\n",
    "  remove_columns=split_datasets['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-100` represents the padding values that should not be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView({'input_ids': tensor([[54596,  2765,   594, 10110,    15,     8,   632,    60,     0],\n",
       "        [  457,     0, 65000, 65000, 65000, 65000, 65000, 65000, 65000]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[    8,   632,    60,     8,    12,  9613,   637, 56891,     0],\n",
       "        [    8, 46315,     0,  -100,  -100,  -100,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[65000,     8,   632,    60,     8,    12,  9613,   637, 56891],\n",
       "        [65000,     8, 46315,     0, 65000, 65000, 65000, 65000, 65000]])})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_dataset['train'][i] for i in range(1, 3)])\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Training Details</u>\n",
    "\n",
    "- Model uses the `decoder_input_ids` with an attention mask to ensure that none of the after tokens are used during prediction\n",
    "- `generate()` is used to generate tokens one by one\n",
    "  - Need to set `predict_with_generate=True`\n",
    "- _BLEU score:_ Evaluates how close generations are to the expected message, penalising for repeated words\n",
    "- For translation tasks: Several sentences are used as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('sacrebleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 46.750469682990165,\n",
       " 'counts': [11, 6, 4, 3],\n",
       " 'totals': [12, 11, 10, 9],\n",
       " 'precisions': [91.66666666666667,\n",
       "  54.54545454545455,\n",
       "  40.0,\n",
       "  33.333333333333336],\n",
       " 'bp': 0.9200444146293233,\n",
       " 'sys_len': 12,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of good translation\n",
    "predictions = [\n",
    "  \"This plugin lets you translate web pages between several languages automatically.\"\n",
    "]\n",
    "references = [\n",
    "  [\n",
    "    \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "  ]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.683602693167689,\n",
       " 'counts': [1, 0, 0, 0],\n",
       " 'totals': [4, 3, 2, 1],\n",
       " 'precisions': [25.0, 16.666666666666668, 12.5, 12.5],\n",
       " 'bp': 0.10539922456186433,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of poor translation\n",
    "predictions = [\"This This This This\"]\n",
    "references = [\n",
    "  [\n",
    "    \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "  ]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  preds, labels = eval_preds\n",
    "\n",
    "  # If the model returns more than the prediction logits\n",
    "  if isinstance(preds, tuple):\n",
    "    preds = preds[0]\n",
    "  \n",
    "  decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "  # Replace -100s in labels\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "  # Simple post-processing\n",
    "  decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "  decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "  result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "  return {'bleu': result['score']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2547/2852970220.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='438' max='219' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [219/219 29:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.4871249198913574,\n",
       " 'eval_model_preparation_time': 0.0017,\n",
       " 'eval_bleu': 28.04402379160332,\n",
       " 'eval_runtime': 638.9095,\n",
       " 'eval_samples_per_second': 21.861,\n",
       " 'eval_steps_per_second': 0.343}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "args = Seq2SeqTrainingArguments(\n",
    "  \"marian-finetuned-kd4e-en-to-ch_ZN\",\n",
    "  eval_strategy=\"no\",\n",
    "  save_strategy=\"epoch\",\n",
    "  learning_rate=2e-5,\n",
    "  per_device_train_batch_size=32,\n",
    "  per_device_eval_batch_size=64,\n",
    "  weight_decay=0.01,\n",
    "  save_total_limit=3,\n",
    "  num_train_epochs=3,\n",
    "  predict_with_generate=True,\n",
    "  fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "  model,\n",
    "  args,\n",
    "  train_dataset=tokenized_dataset['train'],\n",
    "  eval_dataset=tokenized_dataset['validation'],\n",
    "  data_collator=data_collator,\n",
    "  tokenizer=tokenizer,\n",
    "  compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.evaluate(max_length=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11787' max='11787' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11787/11787 12:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.558700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.288300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.174200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.995100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.994200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.988300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.926900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.926200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.905300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.897700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.902700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Software/venv/py310_ubun_venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[65000]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9346717596054077,\n",
       " 'eval_model_preparation_time': 0.0017,\n",
       " 'eval_bleu': 41.547050185618154,\n",
       " 'eval_runtime': 264.7145,\n",
       " 'eval_samples_per_second': 52.763,\n",
       " 'eval_steps_per_second': 0.827,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the training loop\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate(max_length=MAXLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model improved from BLEU score of 28.04 -> 41.55 which is a pretty good result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Pytorch training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(\"torch\")\n",
    "train_dataloader = DataLoader(\n",
    "  tokenized_dataset['train'],\n",
    "  shuffle=True,\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=8\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "  tokenized_dataset['validation'],\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "  model, optimizer, train_dataloader, eval_dataloader\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "  \"linear\",\n",
    "  optimizer=optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "  predictions = predictions.cpu().numpy()\n",
    "  labels = labels.cpu().numpy()\n",
    "\n",
    "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "  # Replace -100 in the labels as we can't decode them.\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "  # Some simple post-processing\n",
    "  decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "  decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "  return decoded_preds, decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "  model.train()\n",
    "  for batch in train_dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    accelerator.backward(loss)\n",
    "\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    progress_bar.update(1)\n",
    "  \n",
    "  # Evaluation at each epoch\n",
    "  model.eval()\n",
    "  for batch in tqdm(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "      generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "        batch['input_ids'],\n",
    "        attention_mask=batch['attention_mask'],\n",
    "        max_length=128\n",
    "      )\n",
    "    labels = batch['labels']\n",
    "\n",
    "    # Pad predictions and labels before gathering\n",
    "    generated_tokens = accelerator.pad_across_process(\n",
    "      generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "    )\n",
    "    labels = accelerator.pad_across_process(\n",
    "      labels, dim=1, pad_index=-100\n",
    "    )\n",
    "\n",
    "    # Gather predictions\n",
    "    predictions_gathered = accelerator.gather(generated_tokens)\n",
    "    labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess(predcitions_gathered, labels_gathered)\n",
    "    metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "  \n",
    "results = metric.compute()\n",
    "print(f\"epoch {epoch}, BLEU score: {results['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the model\n",
    "# accelerator.wait_for_everyone()\n",
    "# unwrapped_model = accelerator.unwrap_model(model)\n",
    "# unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "# if accelerator.is_main_process:\n",
    "#   tokenizer.save_pretrained(output_dir)\n",
    "#   repo.push_to_hub(\n",
    "#     commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "#   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer_test = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "translator_test = pipeline('translation', model=model, tokenizer=tokenizer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'ÈªòËÆ§Âà∞Êâ©Â±ïÁ∫øÊù°'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator_test(\"Default to expanded threads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Summarisation\n",
    "\n",
    "Challenging NLP task that requires the model to understand long passages and generate coherent text that capture the main topic\n",
    "\n",
    "- ü§ñ Output: Bilingual English & Spanish model that summarises customer reviews\n",
    "- üíæ Dataset: Multilingual Amazon Reviews Corpus\n",
    "  - Use the title as the target summaries\n",
    "\n",
    "‚úíÔ∏è NOTE: Dataset doesn't exist on HF, so take from: https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi/data?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476bedc8bb1e48f7a9f882f6dc7cdfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ce884599394aa3b8bf6b60cd819c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dbc9d31a0845e493f9bd18b26b7bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc9eaabe4f745b89dfb3893bdf225fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b417d1c380d940548d0db78ad1430a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613f9d60e542454bbda178ac1ccec94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/30000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 200000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\"train\": \"train.csv\", \"validation\": \"validation.csv\", \"test\": \"test.csv\"}\n",
    "total_dataset = load_dataset(\"./data/amazon_review_multi\", data_files=data_files)\n",
    "\n",
    "eng_dataset = total_dataset.filter(lambda x: x['language'] == 'en')\n",
    "spa_dataset = total_dataset.filter(lambda x: x['language'] == 'es')\n",
    "eng_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Target: Title (summary) | Data: Review body\n",
    "- Selecting only book and ebook reviews\n",
    "- Remove examples with short titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Title: Worked in front position, not rear\n",
      ">> Review: 3 stars because these are not rear brakes as stated in the item description. At least the mount adapter only worked on the front fork of the bike that I got it for.\n",
      "\n",
      ">> Title: meh\n",
      ">> Review: Does it‚Äôs job and it‚Äôs gorgeous but mine is falling apart, I had to basically put it together again with hot glue\n",
      "\n",
      ">> Title: Can't beat these for the money\n",
      ">> Review: Bought this for handling miscellaneous aircraft parts and hanger \"stuff\" that I needed to organize; it really fit the bill. The unit arrived quickly, was well packaged and arrived intact (always a good sign). There are five wall mounts-- three on the top and two on the bottom. I wanted to mount it on the wall, so all I had to do was to remove the top two layers of plastic drawers, as well as the bottom corner drawers, place it when I wanted and mark it; I then used some of the new plastic screw in wall anchors (the 50 pound variety) and it easily mounted to the wall. Some have remarked that they wanted dividers for the drawers, and that they made those. Good idea. My application was that I needed something that I can see the contents at about eye level, so I wanted the fuller-sized drawers. I also like that these are the new plastic that doesn't get brittle and split like my older plastic drawers did. I like the all-plastic construction. It's heavy duty enough to hold metal parts, but being made of plastic it's not as heavy as a metal frame, so you can easily mount it to the wall and still load it up with heavy stuff, or light stuff. No problem there. For the money, you can't beat it. Best one of these I've bought to date-- and I've been using some version of these for over forty years.\n"
     ]
    }
   ],
   "source": [
    "def show_samples(\n",
    "  dataset: datasets.dataset_dict.DatasetDict, \n",
    "  num_samples: int=3,\n",
    "  seed: int=42\n",
    "):\n",
    "  sample = dataset['train'].shuffle(seed=seed).select(range(num_samples))\n",
    "  for example in sample:\n",
    "    print(f\"\\n>> Title: {example['review_title']}\")\n",
    "    print(f\">> Review: {example['review_body']}\")\n",
    "\n",
    "show_samples(eng_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0006195bd00e46ddb6f6e5aeaa9d4f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87707c90d5374be5a0e2da6c9ff777b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20ba198621c4392934a45b14ff8e458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7bae750c3a43b69c3ff7b95d8f5276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf8caa010bb4fe1b944980d895a4f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12baf40b3d49447a9a072ad87ffb9d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Title: I'm dissapointed.\n",
      ">> Review: I guess I had higher expectations for this book from the reviews. I really thought I'd at least like it. The plot idea was great. I loved Ash but, it just didnt go anywhere. Most of the book was about their radio show and talking to callers. I wanted the author to dig deeper so we could really get to know the characters. All we know about Grace is that she is attractive looking, Latino and is kind of a brat. I'm dissapointed.\n",
      "\n",
      ">> Title: Good art, good price, poor design\n",
      ">> Review: I had gotten the DC Vintage calendar the past two years, but it was on backorder forever this year and I saw they had shrunk the dimensions for no good reason. This one has good art choices but the design has the fold going through the picture, so it's less aesthetically pleasing, especially if you want to keep a picture to hang. For the price, a good calendar\n",
      "\n",
      ">> Title: Helpful\n",
      ">> Review: Nearly all the tips useful and. I consider myself an intermediate to advanced user of OneNote. I would highly recommend.\n"
     ]
    }
   ],
   "source": [
    "# Additional filtering on books and ebooks to reduce dataset size\n",
    "def filter_books(example: dict):\n",
    "  return (\n",
    "    example['product_category'] == \"book\" or\n",
    "    example['product_category'] == \"digital_ebook_purchase\"\n",
    "  )\n",
    "\n",
    "eng_books = eng_dataset.filter(filter_books)\n",
    "spa_books = spa_dataset.filter(filter_books)\n",
    "show_samples(eng_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Title: Easy to follow!!!!\n",
      ">> Review: I loved The dash diet weight loss Solution. Never hungry. I would recommend this diet. Also the menus are well rounded. Try it. Has lots of the information need thanks.\n",
      "\n",
      ">> Title: PARCIALMENTE DA√ëADO\n",
      ">> Review: Me lleg√≥ el d√≠a que tocaba, junto a otros libros que ped√≠, pero la caja lleg√≥ en mal estado lo cual da√±√≥ las esquinas de los libros porque ven√≠an sin protecci√≥n (forro).\n",
      "\n",
      ">> Title: no lo he podido descargar\n",
      ">> Review: igual que el anterior\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the english and spanish datasets\n",
    "books_dataset = DatasetDict()\n",
    "\n",
    "for split in eng_books.keys():\n",
    "  books_dataset[split] = concatenate_datasets(\n",
    "    [eng_books[split], spa_books[split]]\n",
    "  )\n",
    "  books_dataset[split] = books_dataset[split].shuffle(seed=42)\n",
    "\n",
    "show_samples(books_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb61e9855f2e40a890c6b3a38496a6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17612 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d07cae464d4c20803b50afe0ff9f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/424 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07f59b4032a4d29bfabe040477c1787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 9672\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 238\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove titles with 1-2 words (heuristic: split on whitespace)\n",
    "books_dataset = books_dataset.filter(lambda x: len(x['review_title'].split(\" \")) > 2)\n",
    "books_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-06-18T19:03:45.452311+08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 8.31.0\n",
      "\n",
      "Compiler    : MSC v.1938 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 183 Stepping 1, GenuineIntel\n",
      "CPU cores   : 20\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_ubun_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
