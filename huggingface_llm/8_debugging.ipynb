{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Models\n",
    "\n",
    "How to debug the training loop and how to ask the community for help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 09/01/2026   | Martin | Created   | Notebook created for debugging LLM models | \n",
    "| 13/01/2026   | Martin | Update   | Debugging missing files from cloned repos | \n",
    "| 14/01/2026   | Martin | Update   | Debugging training loop and silent error notes | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Debugging Repo Files](#debugging-repo-files)\n",
    "* [Debugging Training Loop](#debugging-training-loop)\n",
    "* [Debugging Silent Errors](#debugging-silent-errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- What to do when you get an error\n",
    "- How to ask for help on forums\n",
    "- How to debug the training pipeline\n",
    "- How to write good issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Repo Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "from huggingface_hub import (\n",
    "  notebook_login,\n",
    "  Repository,\n",
    "  snapshot_download,\n",
    "  create_repo,\n",
    "  get_full_repo_name,\n",
    "  list_repo_files\n",
    ")\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9d7c864eb64194b15a907577350f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bda02b6b3245dba5e236d71b79e16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Software/venv/py310_ubun_venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://huggingface.co/Minimartzz/distilbert-base-uncased-finetuned-squad-d5716d28 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28b8b71b23942969480ddfc31fb8da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/253M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76f1e8e52f04acb9881d8c67e597b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin:   0%|          | 1.00/2.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Minimartzz/distilbert-base-uncased-finetuned-squad-d5716d28\n",
      "   d974578..c0ac1a5  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a repository\n",
    "def copy_repository_template():\n",
    "  # Clone the repo and extract local path\n",
    "  template_repo_id = \"lewtun/distilbert-base-uncased-finetuned-squad-d5716d28\"\n",
    "  commit_hash = \"be3eaffc28669d7932492681cd5f3e8905e358b4\"\n",
    "  template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)\n",
    "\n",
    "  # Create empty repo on the hub\n",
    "  model_name = template_repo_id.split(\"/\")[1]\n",
    "  create_repo(model_name, exist_ok=True)\n",
    "\n",
    "  # Clone empty repo\n",
    "  new_repo_id = get_full_repo_name(model_name)\n",
    "  new_repo_dir = model_name\n",
    "  repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)\n",
    "\n",
    "  # Copy files\n",
    "  copy_tree(template_repo_dir, new_repo_dir)\n",
    "\n",
    "  # Push to hub\n",
    "  repo.push_to_hub()\n",
    "\n",
    "copy_repository_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gitattributes',\n",
       " 'README.md',\n",
       " 'pytorch_model.bin',\n",
       " 'special_tokens_map.json',\n",
       " 'tokenizer_config.json',\n",
       " 'training_args.bin',\n",
       " 'vocab.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all files inside the repository\n",
    "model_checkpoint = get_full_repo_name(\"distilbert-base-uncased-finetuned-squad-d5716d28\")\n",
    "list_repo_files(repo_id=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a7e9d1dd5b4f36a3ed01a379c2f8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249b98c7e3d4413d8a06910d9a03b18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Minimartzz/distilbert-base-uncased-finetuned-squad-d5716d28/commit/e711a54e18cc9f379c9d9d37ae52ad20e7a99027', commit_message='Add config.json', commit_description='', oid='e711a54e18cc9f379c9d9d37ae52ad20e7a99027', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Minimartzz/distilbert-base-uncased-finetuned-squad-d5716d28', endpoint='https://huggingface.co', repo_type='model', repo_id='Minimartzz/distilbert-base-uncased-finetuned-squad-d5716d28'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing config file, so get from the original model to push to repo\n",
    "pretrained_config = \"distilbert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(pretrained_config)\n",
    "\n",
    "config.push_to_hub(model_checkpoint, commit_message=\"Add config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gitattributes',\n",
       " 'README.md',\n",
       " 'config.json',\n",
       " 'pytorch_model.bin',\n",
       " 'special_tokens_map.json',\n",
       " 'tokenizer_config.json',\n",
       " 'training_args.bin',\n",
       " 'vocab.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check again\n",
    "list_repo_files(repo_id=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pipeline(\"question-answering\", model=model_checkpoint, revision=\"main\")\n",
    "\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text\n",
    "given a question. An example of a question answering dataset is the SQuAD\n",
    "dataset, which is entirely based on that task. If you would like to fine-tune a\n",
    "model on a SQuAD task, you may leverage the\n",
    "examples/pytorch/question-answering/run_squad.py script.\n",
    "\n",
    "ðŸ¤— Transformers is interoperable with the PyTorch, TensorFlow, and JAX\n",
    "frameworks, so you can use your favourite tools for a wide variety of tasks!\n",
    "\"\"\"\n",
    "\n",
    "question = \"What is extractive question answering?\"\n",
    "reader(question=question, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Training Loop\n",
    "\n",
    "- Explicitly pass in the right data collator in the `Trainer()` class\n",
    "- CUDA errors only show up during batch collation, so the error shown does not always reflect when it occurred. Switch to __CPU__ using `trainer.model.cpu()(**batch)` to find out where the error is happening\n",
    "  - Before rerunning, test it on a single batch on the GPU\n",
    "- For CUDA Out-of-Memory errors -> Reduce batch size\n",
    "- Always run `trainer.evaluate()` before launching `trainer.train()` to avoid wasting resources by running the entire training loop\n",
    "\n",
    "Test on a single batch\n",
    "\n",
    "```python\n",
    "for batch in trainer.get_eval_dataloader():\n",
    "  break\n",
    "\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "  outputs = trainer.model(**batch)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample of completed training loop for finetuning a BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "  AutoTokenizer,\n",
    "  AutoModelForSequenceClassification,\n",
    "  DataCollatorWithPadding,\n",
    "  TrainingArguments,\n",
    "  Trainer,\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "raw_datasets = load_dataset(\"glue\", \"mnli\")\n",
    "\n",
    "# Define the base model\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Preprocessing (tokenizing) raw data\n",
    "def preprocess_function(examples):\n",
    "  return tokenizer(examples[\"premise\"], examples[\"hypothesis\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)\n",
    "\n",
    "# Define the training arguments\n",
    "args = TrainingArguments(\n",
    "    f\"distilbert-finetuned-mnli\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Define the metrics used\n",
    "metric = evaluate.load(\"glue\", \"mnli\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  predictions, labels = eval_pred\n",
    "  predictions = np.argmax(predictions, axis=1)\n",
    "  return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# ALERT: Explicitly specify the data collator being used\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Run the training loop\n",
    "trainer = Trainer(\n",
    "  model,\n",
    "  args,\n",
    "  train_dataset=tokenized_datasets[\"train\"],\n",
    "  eval_dataset=tokenized_datasets[\"validation_matched\"],\n",
    "  compute_metrics=compute_metrics,\n",
    "  data_collator=data_collator,\n",
    "  tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Silent Errors\n",
    "\n",
    "These are errors that don't show up as tracebacks or errors. When the model trains to completing and is evaluated, but the results are poor\n",
    "\n",
    "- __Sanity check your data__ - Ensure that the inputs and outputs match expectations. Then run an evaluation on a batch of correctly labeled data to check if the score is similar\n",
    "- __Ensure that model performs better than random guessing__ - If the loss/metric on the initial model is very different from the loss/metric on random predictions, likely something is wrong with how it's computed\n",
    "- __Overfit model on a single batch__ - The model should achieve close to perfect results, if not something is wrong\n",
    "- __Don't tune anything until you establish a baseline__ - Try changing values for a single hyperparater at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_ubun_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
