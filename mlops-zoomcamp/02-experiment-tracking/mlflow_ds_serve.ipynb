{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mlflow Datasets & Serving\n",
    "\n",
    "Exploring Mlflow Datasets & Serving API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 13/01/2026   | Martin | Created   | Notebook to explore Mlflow datasets and serving | \n",
    "| 14/01/2026   | Martin | Updated   | Explored datasets and serving APIs | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Datasets](#datasets)\n",
    "* [Serving](#serving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\"../.env\")\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = config[\"MLFLOW_USER\"]\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = config[\"MLFLOW_PASSWORD\"]\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://127.0.0.1:9000\"\n",
    "os.environ[\"MLFLOW_S3_IGNORE_TLS\"] = \"true\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "_Adapted from: https://mlflow.org/docs/latest/ml/dataset/_\n",
    "\n",
    "Features:\n",
    "\n",
    "- __Data Lineage__: Track the complete journey from raw data sources to model inputs\n",
    "- __Reproducibility__: Ensure experiments can be reproduced with identical datasets\n",
    "- __Version Control__: Manage different versions of datasets as they evolve\n",
    "- __Collaboration__: Share datasets and their metadata across teams\n",
    "- __Evaluation Integration__: Seamlessly integrate with MLflow's evaluation capabilities\n",
    "- __Production Monitoring__: Track datasets used in production inference and evaluation\n",
    "\n",
    "Advanced workflows found under _\"Advanced Dataset Management\"_ section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import mlflow\n",
    "import mlflow.data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow/4', creation_time=1768273092652, experiment_id='4', last_update_time=1768273092652, lifecycle_stage='active', name='mlflow-datasets-api', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"mlflow-datasets-api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run sneaky-gnat-637 at: http://127.0.0.1:5000/#/experiments/4/runs/475ead24e5f149c293000aa1dc4dfaca\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\venv\\py311\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:148: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "d:\\Software\\venv\\py311\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset_source_url = \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\"\n",
    "raw_data = pd.read_csv(dataset_source_url, delimiter=\";\")\n",
    "\n",
    "# Create a Dataset object\n",
    "dataset = mlflow.data.from_pandas(\n",
    "  raw_data,\n",
    "  source=dataset_source_url,\n",
    "  name=\"wine-quality-white\",\n",
    "  targets=\"quality\"\n",
    ")\n",
    "\n",
    "# Log the dataset to an MLflow run\n",
    "with mlflow.start_run():\n",
    "  mlflow.log_input(dataset, context=\"training\", tags={'tag1': 'nice', 'tag2': 'try'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Polars, saving with predictions from a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\venv\\py311\\Lib\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\Software\\venv\\py311\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:148: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "d:\\Software\\venv\\py311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e0b4c07fbc44a489fb998c5423337e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\venv\\py311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run whimsical-pig-554 at: http://127.0.0.1:5000/#/experiments/4/runs/845d98b9e982460d8f1615530b2b7551\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "raw_data_pl = pl.from_pandas(raw_data)\n",
    "\n",
    "# Split data\n",
    "train = raw_data_pl.sample(fraction=0.8, shuffle=True)\n",
    "test = raw_data_pl.sample(fraction=0.2, shuffle=True)\n",
    "\n",
    "y_train = train.select('quality')\n",
    "X_train = train.drop('quality')\n",
    "\n",
    "y_test = test.select('quality')\n",
    "X_test = test.drop('quality')\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "preds = rfc.predict(X_test)\n",
    "pred_proba = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "eval_data = X_test.clone()\n",
    "eval_data = eval_data.with_columns(\n",
    "  quality=y_test.to_numpy().flatten(),\n",
    "  prediction=preds,\n",
    "  prediction_proba=pred_proba\n",
    ")\n",
    "\n",
    "eval_dataset = mlflow.data.from_polars(\n",
    "  eval_data,\n",
    "  source=dataset_source_url,\n",
    "  name=\"wine-quality-evaluation\",\n",
    "  targets=\"quality\", # These are column names from the dataset\n",
    "  predictions=\"prediction\"\n",
    ")\n",
    "\n",
    "with mlflow.start_run():\n",
    "  mlflow.log_input(eval_dataset, context='evaluation')\n",
    "\n",
    "  mlflow.sklearn.log_model(\n",
    "    sk_model=rfc,\n",
    "    name=\"wine-quality-classifier\",\n",
    "    input_example=X_test[0].to_numpy()\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata is stored in the dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: wine-quality-white\n",
      "Dataset digest: 2a1e42c4\n",
      "Dataset source: <mlflow.data.http_dataset_source.HTTPDatasetSource object at 0x000002044E33B290>\n",
      "Dataset profile: {'num_rows': 4898, 'num_elements': 58776}\n",
      "Dataset schema: ['fixed acidity': double (required), 'volatile acidity': double (required), 'citric acid': double (required), 'residual sugar': double (required), 'chlorides': double (required), 'free sulfur dioxide': double (required), 'total sulfur dioxide': double (required), 'density': double (required), 'pH': double (required), 'sulphates': double (required), 'alcohol': double (required), 'quality': long (required)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset name: {dataset.name}\")  # Defaults to \"dataset\" if not specified\n",
    "print(f\"Dataset digest: {dataset.digest}\")  # Unique hash identifier (computed automatically)\n",
    "print(f\"Dataset source: {dataset.source}\")  # DatasetSource object\n",
    "print(f\"Dataset profile: {dataset.profile}\")  # Optional: implementation-specific statistics\n",
    "print(f\"Dataset schema: {dataset.schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving data from previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded 4898 rows from C:\\Users\\User\\AppData\\Local\\Temp\\tmpzfezieya\\winequality-white.csv\n"
     ]
    }
   ],
   "source": [
    "run_id = \"abed61c56e824cfc841dbc1c94137895\"\n",
    "\n",
    "logged_run = mlflow.get_run(run_id)\n",
    "logged_dataset = logged_run.inputs.dataset_inputs[0].dataset\n",
    "\n",
    "# Get the data source and reload data\n",
    "dataset_source = mlflow.data.get_source(logged_dataset)\n",
    "local_path = dataset_source.load()  # Downloads to local temp file\n",
    "\n",
    "# Reload the data\n",
    "reloaded_data = pd.read_csv(local_path, delimiter=\";\")\n",
    "print(f\"Reloaded {len(reloaded_data)} rows from {local_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset versioning\n",
    "\n",
    "Track datasets as they evolve. Mainly for metadata management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_versioned_dataset(data, version, base_name=\"customer-data\"):\n",
    "  \"\"\"Create a versioned dataset with metadata.\"\"\"\n",
    "\n",
    "  dataset = mlflow.data.from_pandas(\n",
    "    data,\n",
    "    source=f\"data_pipeline_v{version}\",\n",
    "    name=f\"{base_name}-v{version}\",\n",
    "    targets=\"target\",\n",
    "  )\n",
    "\n",
    "  with mlflow.start_run(run_name=f\"Dataset_Version_{version}\"):\n",
    "    mlflow.log_input(dataset, context=\"versioning\")\n",
    "\n",
    "    # Log version metadata\n",
    "    mlflow.log_params(\n",
    "      {\n",
    "        \"dataset_version\": version,\n",
    "        \"data_size\": len(data),\n",
    "        \"features_count\": len(data.columns) - 1,\n",
    "        \"target_distribution\": data[\"target\"].value_counts().to_dict(),\n",
    "      }\n",
    "    )\n",
    "\n",
    "    # Log data quality metrics\n",
    "    mlflow.log_metrics(\n",
    "      {\n",
    "        \"missing_values_pct\": (data.isnull().sum().sum() / data.size) * 100,\n",
    "        \"duplicate_rows\": data.duplicated().sum(),\n",
    "        \"target_balance\": data[\"target\"].std(),\n",
    "      }\n",
    "    )\n",
    "\n",
    "  return dataset\n",
    "\n",
    "\n",
    "# Create multiple versions\n",
    "v1_dataset = create_versioned_dataset(data_v1, \"1.0\")\n",
    "v2_dataset = create_versioned_dataset(data_v2, \"2.0\")\n",
    "v3_dataset = create_versioned_dataset(data_v3, \"3.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch prediction monitoring\n",
    "\n",
    "Record the results of a model's batch prediction on production data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_batch_predictions(batch_data, model_version, date):\n",
    "  \"\"\"Monitor production batch prediction datasets.\"\"\"\n",
    "\n",
    "  # Create dataset for batch predictions\n",
    "  batch_dataset = mlflow.data.from_pandas(\n",
    "    batch_data,\n",
    "    source=f\"production_batch_{date}\",\n",
    "    name=f\"batch_predictions_{date}\",\n",
    "    targets=\"true_label\" if \"true_label\" in batch_data.columns else None,\n",
    "    predictions=\"prediction\" if \"prediction\" in batch_data.columns else None,\n",
    "  )\n",
    "\n",
    "  with mlflow.start_run(run_name=f\"Batch_Monitor_{date}\"):\n",
    "    mlflow.log_input(batch_dataset, context=\"production_batch\")\n",
    "\n",
    "    # Log production metadata\n",
    "    mlflow.log_params(\n",
    "      {\n",
    "        \"batch_date\": date,\n",
    "        \"model_version\": model_version,\n",
    "        \"batch_size\": len(batch_data),\n",
    "        \"has_ground_truth\": \"true_label\" in batch_data.columns,\n",
    "      }\n",
    "    )\n",
    "\n",
    "    # Monitor prediction distribution\n",
    "    if \"prediction\" in batch_data.columns:\n",
    "      pred_metrics = {\n",
    "        \"prediction_mean\": batch_data[\"prediction\"].mean(),\n",
    "        \"prediction_std\": batch_data[\"prediction\"].std(),\n",
    "        \"unique_predictions\": batch_data[\"prediction\"].nunique(),\n",
    "      }\n",
    "      mlflow.log_metrics(pred_metrics)\n",
    "\n",
    "    # Evaluate if ground truth is available\n",
    "    if all(col in batch_data.columns for col in [\"prediction\", \"true_label\"]):\n",
    "      result = mlflow.models.evaluate(data=batch_dataset, model_type=\"classifier\")\n",
    "      print(f\"Batch accuracy: {result.metrics.get('accuracy_score', 'N/A')}\")\n",
    "\n",
    "  return batch_dataset\n",
    "\n",
    "\n",
    "# Usage\n",
    "batch_dataset = monitor_batch_predictions(daily_batch_data, \"v2.1\", \"2024-01-15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices\n",
    "\n",
    "1. __Ensure data quality__ - Validate data quality before logging\n",
    "2. __Consistent naming convention__ - Consistent, descriptive names including version information\n",
    "3. __Source documentation__ - Always specify meaningful source URLs or identifiers that allow you to trace back to the original data\n",
    "4. __Context specification__ - Use clear `context`\n",
    "5. __Metadata logging__ - Include relevant metadata (e.g data collection, preprocessing steps, data characteristics)\n",
    "6. __Version control__ - Track versions explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving\n",
    "\n",
    "Toolkit to deply models to various targets: local environment, cloud services, Kubernetes\n",
    "\n",
    "- __Mlflow Model__ - Standard format that packages a ML model with metadata. Created when models are logged\n",
    "- __Docker Containers__ - Uses Docker containers to package models with dependencies\n",
    "- __Deployment Target__ - Destination environment for the model\n",
    "\n",
    "<u>How it works</u>\n",
    "\n",
    "1. Mlflow packages model and dependencies into virtual env or docker container\n",
    "2. Launch inference server with REST endpoints (e.g FastAPI)\n",
    "3. Exposes API based on specifications\n",
    "\n",
    "Generally, there are 2 modules:\n",
    "\n",
    "- mlflow models: for local deployment\n",
    "- mlflow deployments: for custom targets (e.g Sagemaker, Azure, Databricks, Kubernetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference details\n",
    "\n",
    "4 main endpoints:\n",
    "\n",
    "1. `/invocations` - Inference endpoint that accepts POST requests with input data and returns predictions\n",
    "2. `/ping` - Used for health checks\n",
    "3. `/health` - Same as /ping\n",
    "4. `/version` - Returns the Mlflow version\n",
    "\n",
    "`/invocations` accepts both CSV and JSON inputs by specifying the Content-Type header as `application/csv` or `application/json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': [0, 1],\n",
       " 'columns': ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol'],\n",
       " 'data': [[7.0, 0.27, 0.36, 20.7, 0.045, 45.0, 170.0, 1.001, 3.0, 0.45, 8.8],\n",
       "  [6.3, 0.3, 0.34, 1.6, 0.049, 14.0, 132.0, 0.994, 3.3, 0.49, 9.5]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.iloc[0:2].drop('quality', axis=1).to_dict(orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [6, 6]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"dataframe_split\": raw_data.iloc[0:2].drop('quality', axis=1).to_dict(orient='split')\n",
    "})\n",
    "\n",
    "response = requests.post(\n",
    "  url=f\"http://localhost:5001/invocations\",\n",
    "  data=payload,\n",
    "  headers={\"Content-Type\": \"application/json\"}\n",
    ")\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of an OpenAI message post request with params. Params must be defined in the model signature to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = json.dumps(\n",
    "  {\n",
    "    \"inputs\": {\"messages\": [{\"role\": \"user\", \"content\": \"Tell a joke!\"}]},\n",
    "    \"params\": {\n",
    "      \"temperature\": 0.5,\n",
    "      \"max_tokens\": 20,\n",
    "    },\n",
    "  }\n",
    ")\n",
    "response = requests.post(\n",
    "  url=f\"http://localhost:5678/invocations\",\n",
    "  data=payload,\n",
    "  headers={\"Content-Type\": \"application/json\"},\n",
    ")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow models serve -m runs:/845d98b9e982460d8f1615530b2b7551/wine-quality-classifier -p 5001 -h 0.0.0.0 --no-conda\n"
     ]
    }
   ],
   "source": [
    "run_id = \"845d98b9e982460d8f1615530b2b7551\"\n",
    "print(f\"mlflow models serve -m runs:/{run_id}/wine-quality-classifier -p 5001 -h 0.0.0.0 --no-conda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post request for inference\n",
    "\n",
    "`curl http://127.0.0.1:5001/invocations -H \"content-Type:application/json\" --data '{\"inputs\": [[7.0, 0.27, 0.36, 20.7, 0.045, 45.0, 170.0, 1.0010, 3.00, 0.45, 8.8]]}'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a docker image\n",
    "\n",
    "<u>Requirements to run from host docker client</u>\n",
    "\n",
    "- `boto3` must be installed in Python environment\n",
    "- Following environment variables must be in host machine\n",
    "  * MLFLOW_TRACKING_URI\n",
    "  * MLFLOW_S3_ENDPOINT_URL\n",
    "  * AWS_ACCESS_KEY_ID\n",
    "  * AWS_SECRET_ACCESS_KEY\n",
    "- `/etc/host` file must contain `minio` entry pointing to localhost (optional if configured as such in docker container)\n",
    "\n",
    "NOTE: 8080 is the default port within the container used to host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow models build-docker --model-uri \"runs:/845d98b9e982460d8f1615530b2b7551/wine-quality-classifier\" --name \"wine-classifier-image\"\n"
     ]
    }
   ],
   "source": [
    "# Run this on host machine\n",
    "print(f'mlflow models build-docker --model-uri \"runs:/{run_id}/wine-quality-classifier\" --name \"wine-classifier-image\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run it with `MLServer` as the serving framework instead of FastAPI, add the `--enable-mlserver` flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run -p 5002:8080 wine-classifier-image\n"
     ]
    }
   ],
   "source": [
    "# Then to run the container\n",
    "print(\"docker run -p 5002:8080 wine-classifier-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other deployment options can be found in their documentation here:\n",
    "\n",
    "- [Deploying to Kubernetes](https://mlflow.org/docs/latest/ml/deployment/deploy-model-to-kubernetes/tutorial/)\n",
    "- [Deploying to Sagemaker](https://mlflow.org/docs/latest/ml/deployment/deploy-model-to-sagemaker/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2026-01-14T07:41:11.399676+08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 9.8.0\n",
      "\n",
      "Compiler    : MSC v.1938 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 183 Stepping 1, GenuineIntel\n",
      "CPU cores   : 20\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
